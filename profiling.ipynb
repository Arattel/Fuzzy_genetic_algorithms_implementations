{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.elegant_fuzzy_genetic_algorithms.helpers.generalized_priority_inferencer import GeneralizedPriorityInferencer\n",
    "from src.elegant_fuzzy_genetic_algorithms.helpers.parallel_priority_wrapper import ParallelPriorityWrapper\n",
    "from src.common.fitness import griewank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpi = ParallelPriorityWrapper(5)\n",
    "pi = GeneralizedPriorityInferencer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1  = np.random.uniform(0, 1, 100)\n",
    "c2  = np.random.uniform(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.194834 s\n",
      "File: /home/oleksandr/UT/Thesis/Implementations/src/elegant_fuzzy_genetic_algorithms/helpers/parallel_priority_wrapper.py\n",
      "Function: infer_priority at line 16\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    16                                               def infer_priority(self, c1: np.array, c2: np.array) -> np.array:\n",
      "    17         1      21023.0  21023.0      0.0          indices = np.arange(c1.shape[0])\n",
      "    18         1      96381.0  96381.0      0.0          splits = np.array_split(indices, self.n_processes)\n",
      "    19         1       9847.0   9847.0      0.0          ctx = mp.get_context('fork')\n",
      "    20         1       3841.0   3841.0      0.0          processes = [i for i in range(self.n_processes)]\n",
      "    21                                                   \n",
      "    22         1     468286.0 468286.0      0.2          q = mp.Queue()\n",
      "    23        12     169155.0  14096.2      0.1          for i, split in enumerate(splits):\n",
      "    24        12    2965526.0 247127.2      1.5              processes[i] = ctx.Process(target=infer_priority, args=(self.inferrers[i], c1[split], c2[split], q, i))\n",
      "    25        12   64194491.0 5349540.9     32.9              processes[i].start()\n",
      "    26                                                       \n",
      "    27        12      35759.0   2979.9      0.0          for i  in range(len(processes)):\n",
      "    28        12  126067181.0 10505598.4     64.7              processes[i].join()\n",
      "    29                                                       \n",
      "    30         1     802895.0 802895.0      0.4          return _extract_results(q)"
     ]
    }
   ],
   "source": [
    "%lprun -f gpi.infer_priority gpi.infer_priority(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.820888 s\n",
      "File: /home/oleksandr/UT/Thesis/Implementations/src/elegant_fuzzy_genetic_algorithms/helpers/generalized_priority_inferencer.py\n",
      "Function: infer_priority at line 78\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    78                                               def infer_priority(self, first, second):\n",
      "    79                                           \n",
      "    80        52      94631.0   1819.8      0.0          if first > second:\n",
      "    81        48      63694.0   1327.0      0.0              first, second = second, first\n",
      "    82                                                   \n",
      "    83                                           \n",
      "    84       100     227960.0   2279.6      0.0          self.first_cl.value = first\n",
      "    85       100     178655.0   1786.5      0.0          self.second_cl.value = second\n",
      "    86                                           \n",
      "    87       100  820037482.0 8200374.8     99.9          self.engine.process()\n",
      "    88                                           \n",
      "    89       100     285862.0   2858.6      0.0          return self.priority.value"
     ]
    }
   ],
   "source": [
    "%lprun -f pi.infer_priority [pi.infer_priority(c1[i], c2[i]) for i in range(c1.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation( vector):\n",
    "        n = len(vector)\n",
    "        fr = 4000\n",
    "        s = 0\n",
    "        p = 1\n",
    "        for j in range(n): \n",
    "            s = s+vector[j]**2\n",
    "        for j in range(n): \n",
    "            p = p*np.cos(vector[j]/np.sqrt(j+1))\n",
    "        simulation = [s/fr-p+1]\n",
    "        return simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griewank(genome):\n",
    "    s = np.sum(np.square(genome))\n",
    "    p = np.product(np.cos(genome / (np.sqrt(np.arange(genome.shape[0])+ 1))))\n",
    "    return 1 + ((s) / 4000) - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_arr = np.array([-303.12149335, -552.4613729, -528.0668421, -560.66891845, -307.0115594 ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[272.1305852725559]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation(rand_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272.1305852725559"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "griewank(rand_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a78cde6364742d5eb3c1afb06f5d9ac27359d158d2fd799008b8978ac1916b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
