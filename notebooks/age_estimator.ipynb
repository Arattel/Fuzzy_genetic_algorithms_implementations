{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import os \n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.approximation_helpers import (generate_search_space, init_param_index, estimate_by_index)\n",
    "from src.gendered_selection.faster_fuzzy_logic.parallel_parition_inferrer import ParallelInferrer\n",
    "from src.gendered_selection.faster_fuzzy_logic.generalized_partition_inferrer import GeneralizedInferrer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH: str = './indices/'\n",
    "def age_index_and_y(n_partitions: int = 5) -> str:\n",
    "    name = f'age_gendered_index_{n_partitions}.index'\n",
    "    name_y = f'age_gendered_y_{n_partitions}.pkl'\n",
    "    return os.path.join(BASE_PATH, name), os.path.join(BASE_PATH, name_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedAgeEstimator:\n",
    "    N_POINTS: Union[int, tuple[int]] = 200\n",
    "    def __init__(self, n_partitions: int = 5) -> None:\n",
    "        self.n_partitions = n_partitions\n",
    "\n",
    "        self.index_pth, self.y_pth = age_index_and_y(n_partitions)\n",
    "\n",
    "        # If we have index, we read it. Otherwise, we generate it and cache\n",
    "        if os.path.exists(self.index_pth) and os.path.exists(self.y_pth):\n",
    "            self.index = faiss.read_index(self.index_pth)\n",
    "\n",
    "            with open(self.y_pth, 'rb') as f:\n",
    "                self.y = pkl.load(f) \n",
    "            \n",
    "        else:\n",
    "            self._generate_index()\n",
    "\n",
    "    def _generate_index(self):\n",
    "        # Creating an inferrer\n",
    "        self.inferrer = GeneralizedInferrer(self.n_partitions)\n",
    "\n",
    "        # Creating search space and index\n",
    "        params_combinations = generate_search_space(n_splits=self.N_POINTS, ranges=[(0, 1), (0, 10)])\n",
    "        param_index = init_param_index(params_combinations=params_combinations)\n",
    "\n",
    "        # Generating inference fast\n",
    "        y  = np.array([self.inferrer.infer_partner_age(*params_combinations[i, :]) for i in tqdm(range(params_combinations.shape[0]))])\n",
    "\n",
    "\n",
    "        self.index = param_index\n",
    "        self.y = y\n",
    "\n",
    "        print(os.getcwd())\n",
    "        faiss.write_index(self.index, self.index_pth)\n",
    "\n",
    "        with open(self.y_pth, 'wb') as f:\n",
    "            pkl.dump(self.y, f)\n",
    "\n",
    "        \n",
    "    def preferred_age(self, male_indices_to_reproduce: np.array, lifetime: np.array, population_diversity: float) -> np.array:\n",
    "        lifetimes_male = lifetime[male_indices_to_reproduce]\n",
    "        population_diversity = np.repeat([population_diversity], lifetimes_male.shape[0])\n",
    "        query = np.zeros(shape=(male_indices_to_reproduce.shape[0], 2))\n",
    "        query[:, 0], query[:, 1]  = lifetimes_male, population_diversity\n",
    "        return estimate_by_index(self.index, self.y, query=query).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cae = CachedAgeEstimator(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "pi = ParallelInferrer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 ms ± 139 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cae.preferred_age(np.arange(N), np.random.uniform(0, 1, N), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.62 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.91 s ± 2.05 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pi.multiprocessing_preferred_age(np.arange(N), np.random.uniform(0, 1, N), 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say, that it's at least 10 times faster. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a78cde6364742d5eb3c1afb06f5d9ac27359d158d2fd799008b8978ac1916b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
